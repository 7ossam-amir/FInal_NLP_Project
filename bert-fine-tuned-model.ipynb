{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizer, DistilBertModel\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T16:40:01.458000Z","iopub.execute_input":"2025-05-09T16:40:01.458698Z","iopub.status.idle":"2025-05-09T16:40:01.462672Z","shell.execute_reply.started":"2025-05-09T16:40:01.458673Z","shell.execute_reply":"2025-05-09T16:40:01.461926Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import load_dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nfrom transformers import DistilBertTokenizer, DistilBertModel\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom tqdm import tqdm\nimport pandas as pd\nimport torch\nfrom datasets import load_dataset\nfrom transformers import DistilBertTokenizer, DistilBertModel\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.nn import CrossEntropyLoss\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T16:54:07.643390Z","iopub.execute_input":"2025-05-09T16:54:07.644145Z","iopub.status.idle":"2025-05-09T16:54:07.649736Z","shell.execute_reply.started":"2025-05-09T16:54:07.644122Z","shell.execute_reply":"2025-05-09T16:54:07.648848Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Load dataset\ndataset = load_dataset(\"ucberkeley-dlab/measuring-hate-speech\")\ndf = dataset['train'].to_pandas()[['text', 'violence', 'genocide', 'attack_defend', 'hatespeech']]\n\ndf['violence'] = df['violence'].astype(int)\ndf['genocide'] = df['genocide'].astype(int)\ndf['attack_defend'] = df['attack_defend'].astype(int)\ndf['hatespeech'] = df['hatespeech'].astype(int)\n\nprint(\"Violence distribution:\\n\", df['violence'].value_counts().sort_index())\nprint(\"Genocide distribution:\\n\", df['genocide'].value_counts().sort_index())\nprint(\"Attack/Defend distribution:\\n\", df['attack_defend'].value_counts().sort_index())\nprint(\"Hatespeech distribution:\\n\", df['hatespeech'].value_counts().sort_index())\n\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass HateSpeechMultiLabelDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length=128):\n        self.texts = dataframe['text'].values\n        self.labels = dataframe[['violence', 'genocide', 'attack_defend', 'hatespeech']].values\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        labels = self.labels[idx]\n\n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze(),\n            'labels': torch.tensor(labels, dtype=torch.long)\n        }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntrain_dataset = HateSpeechMultiLabelDataset(train_df, tokenizer)\nval_dataset = HateSpeechMultiLabelDataset(val_df, tokenizer)\ntest_dataset = HateSpeechMultiLabelDataset(test_df, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass BertMultiLabel(torch.nn.Module):\n    def __init__(self, num_classes=5, num_labels=4):\n        super(BertMultiLabel, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_classes * num_labels)\n        self.num_classes = num_classes\n        self.num_labels = num_labels\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]  # CLS token\n        logits = self.classifier(pooled_output)\n        logits = logits.view(-1, self.num_labels, self.num_classes)  # Shape: (batch_size, 4, 5)\n\n        loss = None\n        if labels is not None:\n            loss_fct = CrossEntropyLoss()\n            loss = sum(loss_fct(logits[:, i, :], labels[:, i]) for i in range(self.num_labels))\n\n        return {'loss': loss, 'logits': logits} if loss is not None else {'logits': logits}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = BertMultiLabel(num_classes=5, num_labels=4)\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr=2e-5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training functions\ndef train_epoch(model, data_loader, optimizer, device):\n    model.train()\n    total_loss = 0\n    all_predictions, all_true_labels = [], []\n\n    for batch in data_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs['loss']\n        logits = outputs['logits']\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        preds = torch.argmax(logits, dim=2).cpu().numpy()  # Shape: (batch_size, 4)\n        all_predictions.append(preds)\n        all_true_labels.append(labels.cpu().numpy())\n\n    all_predictions = np.vstack(all_predictions)\n    all_true_labels = np.vstack(all_true_labels)\n    \n    avg_loss = total_loss / len(data_loader)\n    accuracies = [accuracy_score(all_true_labels[:, i], all_predictions[:, i]) for i in range(4)]\n    f1_scores = [f1_score(all_true_labels[:, i], all_predictions[:, i], average='macro') for i in range(4)]\n    return avg_loss, accuracies, f1_scores\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, data_loader, device):\n    model.eval()\n    total_loss = 0\n    all_predictions, all_true_labels = [], []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs['loss']\n            logits = outputs['logits']\n\n            total_loss += loss.item()\n            preds = torch.argmax(logits, dim=2).cpu().numpy()\n            all_predictions.append(preds)\n            all_true_labels.append(labels.cpu().numpy())\n\n    all_predictions = np.vstack(all_predictions)\n    all_true_labels = np.vstack(all_true_labels)\n\n    avg_loss = total_loss / len(data_loader)\n    accuracies = [accuracy_score(all_true_labels[:, i], all_predictions[:, i]) for i in range(4)]\n    f1_scores = [f1_score(all_true_labels[:, i], all_predictions[:, i], average='macro') for i in range(4)]\n    return avg_loss, accuracies, f1_scores\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nnum_epochs = 3\nbest_val_f1 = 0\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch + 1}/{num_epochs}')\n    \n   \n    train_loss, train_accs, train_f1s = train_epoch(model, train_loader, optimizer, device)\n    print(f'Train Loss: {train_loss:.4f}')\n    for i, label in enumerate(['Violence', 'Genocide', 'Attack/Defend', 'Hatespeech']):\n        print(f'{label} - Accuracy: {train_accs[i]:.4f}, Macro F1: {train_f1s[i]:.4f}')\n    \n    val_loss, val_accs, val_f1s = evaluate(model, val_loader, device)\n    print(f'Validation Loss: {val_loss:.4f}')\n    for i, label in enumerate(['Violence', 'Genocide', 'Attack/Defend', 'Hatespeech']):\n        print(f'{label} - Accuracy: {val_accs[i]:.4f}, Macro F1: {val_f1s[i]:.4f}')\n    \n    avg_val_f1 = np.mean(val_f1s)\n    if avg_val_f1 > best_val_f1:\n        best_val_f1 = avg_val_f1\n        torch.save(model.state_dict(), 'best_bert_multilabel.pt')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel.load_state_dict(torch.load('best_bert_multilabel.pt'))\ntest_loss, test_accs, test_f1s = evaluate(model, test_loader, device)\nprint(f'Test Loss: {test_loss:.4f}')\nfor i, label in enumerate(['Violence', 'Genocide', 'Attack/Defend', 'Hatespeech']):\n    print(f'{label} - Accuracy: {test_accs[i]:.4f}, Macro F1: {test_f1s[i]:.4f}')\n\nmodel.eval()\nall_predictions, all_true_labels = [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs['logits'], dim=2).cpu().numpy()\n        all_predictions.append(preds)\n        all_true_labels.append(labels.cpu().numpy())\n\nall_predictions = np.vstack(all_predictions)\nall_true_labels = np.vstack(all_true_labels)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"\\nPer-class metrics:\")\nlabel_info = [\n    ('Violence', 5),\n    ('Genocide', 5),\n    ('Attack/Defend', 5),\n    ('Hatespeech', 3)\n]\n\nfor i, (label, num_classes) in enumerate(label_info):\n    print(f\"\\n{label}:\")\n    target_names = [f'{label} {j}' for j in range(num_classes)]\n    print(classification_report(all_true_labels[:, i], all_predictions[:, i], target_names=target_names))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef predict(text, model, tokenizer, device, max_length=128):\n    model.eval()\n    encoding = tokenizer(\n        text,\n        add_special_tokens=True,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs['logits']\n        preds = torch.argmax(logits, dim=2).cpu().numpy()[0]\n    \n    return {\n        'violence': preds[0],\n        'genocide': preds[1],\n        'attack_defend': preds[2],\n        'hatespeech': preds[3]\n    }\n\n# Example inference\ntexts = [\n    \"This is a violent threat!\",\n    \"I love peaceful discussions.\",\n    \"You deserve to be hurt for this.\"\n]\nfor text in texts:\n    pred = predict(text, model, tokenizer, device)\n    print(f'Text: {text}')\n    print(f'Predicted Labels: {pred}\\n')\n\n# Save model\ntorch.save(model.state_dict(), './fine_tuned_bert_multilabel.pt')\ntokenizer.save_pretrained('./fine_tuned_bert_multilabel')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T17:32:14.100690Z","iopub.execute_input":"2025-05-09T17:32:14.101346Z","iopub.status.idle":"2025-05-09T18:48:31.698011Z","shell.execute_reply.started":"2025-05-09T17:32:14.101323Z","shell.execute_reply":"2025-05-09T18:48:31.697336Z"}},"outputs":[{"name":"stdout","text":"Violence distribution:\n violence\n0    67922\n1    30727\n2    12241\n3    11262\n4    13404\nName: count, dtype: int64\nGenocide distribution:\n genocide\n0    90058\n1    22838\n2     8107\n3     5301\n4     9252\nName: count, dtype: int64\nAttack/Defend distribution:\n attack_defend\n0     7958\n1    11046\n2    38201\n3    44883\n4    33468\nName: count, dtype: int64\nHatespeech distribution:\n hatespeech\n0    80624\n1     8911\n2    46021\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3830b0a1bdc944738e2e28617dc2178d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82c65b30b7cc4acbb27bfa9cf32a6787"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0598989c97344194aa8e4cfc65708908"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f80f50a26af41faa8af29d70c92e056"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c63ec42ad942bb90f76d039a17d1af"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/3\nTrain Loss: 3.4155\nViolence - Accuracy: 0.5850, Macro F1: 0.3871\nGenocide - Accuracy: 0.7140, Macro F1: 0.3350\nAttack/Defend - Accuracy: 0.5520, Macro F1: 0.4381\nHatespeech - Accuracy: 0.7843, Macro F1: 0.3190\nValidation Loss: 3.3753\nViolence - Accuracy: 0.5846, Macro F1: 0.4055\nGenocide - Accuracy: 0.7139, Macro F1: 0.3284\nAttack/Defend - Accuracy: 0.5614, Macro F1: 0.4506\nHatespeech - Accuracy: 0.7887, Macro F1: 0.5350\nEpoch 2/3\nTrain Loss: 3.2215\nViolence - Accuracy: 0.6008, Macro F1: 0.4183\nGenocide - Accuracy: 0.7196, Macro F1: 0.3541\nAttack/Defend - Accuracy: 0.5829, Macro F1: 0.4818\nHatespeech - Accuracy: 0.7984, Macro F1: 0.5427\nValidation Loss: 3.3599\nViolence - Accuracy: 0.5889, Macro F1: 0.3925\nGenocide - Accuracy: 0.7147, Macro F1: 0.3485\nAttack/Defend - Accuracy: 0.5689, Macro F1: 0.4810\nHatespeech - Accuracy: 0.7901, Macro F1: 0.5360\nEpoch 3/3\nTrain Loss: 3.1025\nViolence - Accuracy: 0.6102, Macro F1: 0.4400\nGenocide - Accuracy: 0.7223, Macro F1: 0.3731\nAttack/Defend - Accuracy: 0.6009, Macro F1: 0.5101\nHatespeech - Accuracy: 0.8061, Macro F1: 0.5498\nValidation Loss: 3.3829\nViolence - Accuracy: 0.5811, Macro F1: 0.4047\nGenocide - Accuracy: 0.7133, Macro F1: 0.3594\nAttack/Defend - Accuracy: 0.5690, Macro F1: 0.4804\nHatespeech - Accuracy: 0.7915, Macro F1: 0.5364\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1875311655.py:190: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_bert_multilabel.pt'))\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: 3.3663\nViolence - Accuracy: 0.5872, Macro F1: 0.4056\nGenocide - Accuracy: 0.7125, Macro F1: 0.3550\nAttack/Defend - Accuracy: 0.5669, Macro F1: 0.4794\nHatespeech - Accuracy: 0.7906, Macro F1: 0.5362\n\nPer-class metrics:\n\nViolence:\n              precision    recall  f1-score   support\n\n  Violence 0       0.65      0.88      0.75      6763\n  Violence 1       0.38      0.18      0.25      3200\n  Violence 2       0.14      0.01      0.01      1187\n  Violence 3       0.30      0.36      0.33      1047\n  Violence 4       0.65      0.75      0.69      1359\n\n    accuracy                           0.59     13556\n   macro avg       0.42      0.44      0.41     13556\nweighted avg       0.52      0.59      0.53     13556\n\n\nGenocide:\n              precision    recall  f1-score   support\n\n  Genocide 0       0.75      0.97      0.85      8987\n  Genocide 1       0.31      0.05      0.08      2361\n  Genocide 2       0.18      0.03      0.06       790\n  Genocide 3       0.22      0.07      0.10       494\n  Genocide 4       0.59      0.84      0.69       924\n\n    accuracy                           0.71     13556\n   macro avg       0.41      0.39      0.36     13556\nweighted avg       0.61      0.71      0.63     13556\n\n\nAttack/Defend:\n                 precision    recall  f1-score   support\n\nAttack/Defend 0       0.36      0.35      0.36       760\nAttack/Defend 1       0.38      0.15      0.21      1143\nAttack/Defend 2       0.57      0.61      0.59      3860\nAttack/Defend 3       0.54      0.58      0.56      4466\nAttack/Defend 4       0.67      0.68      0.68      3327\n\n       accuracy                           0.57     13556\n      macro avg       0.51      0.48      0.48     13556\n   weighted avg       0.56      0.57      0.56     13556\n\n\nHatespeech:\n              precision    recall  f1-score   support\n\nHatespeech 0       0.82      0.89      0.85      8065\nHatespeech 1       0.00      0.00      0.00       883\nHatespeech 2       0.74      0.77      0.76      4608\n\n    accuracy                           0.79     13556\n   macro avg       0.52      0.55      0.54     13556\nweighted avg       0.74      0.79      0.76     13556\n\nText: This is a violent threat!\nPredicted Labels: {'violence': 0, 'genocide': 0, 'attack_defend': 3, 'hatespeech': 0}\n\nText: I love peaceful discussions.\nPredicted Labels: {'violence': 0, 'genocide': 0, 'attack_defend': 2, 'hatespeech': 0}\n\nText: You deserve to be hurt for this.\nPredicted Labels: {'violence': 3, 'genocide': 0, 'attack_defend': 3, 'hatespeech': 0}\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_bert_multilabel/tokenizer_config.json',\n './fine_tuned_bert_multilabel/special_tokens_map.json',\n './fine_tuned_bert_multilabel/vocab.txt',\n './fine_tuned_bert_multilabel/added_tokens.json')"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"!pip install gdown\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T19:11:58.359365Z","iopub.execute_input":"2025-05-09T19:11:58.359673Z","iopub.status.idle":"2025-05-09T19:12:02.012265Z","shell.execute_reply.started":"2025-05-09T19:11:58.359652Z","shell.execute_reply":"2025-05-09T19:12:02.011570Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Save the model locally\ntorch.save(model.state_dict(), 'fine_tuned_bert_multilabel.pt')\ntokenizer.save_pretrained('fine_tuned_bert_multilabel')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T19:12:02.013618Z","iopub.execute_input":"2025-05-09T19:12:02.013851Z","iopub.status.idle":"2025-05-09T19:12:03.109489Z","shell.execute_reply.started":"2025-05-09T19:12:02.013829Z","shell.execute_reply":"2025-05-09T19:12:03.108768Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"('fine_tuned_bert_multilabel/tokenizer_config.json',\n 'fine_tuned_bert_multilabel/special_tokens_map.json',\n 'fine_tuned_bert_multilabel/vocab.txt',\n 'fine_tuned_bert_multilabel/added_tokens.json')"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}